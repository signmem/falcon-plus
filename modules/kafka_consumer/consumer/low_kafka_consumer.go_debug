//适合kafka版本小于0.9.0
package consumer

import (
	"errors"
	"time"

	"github.com/Shopify/sarama"
	nsema "github.com/toolkits/concurrent/semaphore"
	"github.com/wvanbergen/kafka/consumergroup"
	"github.com/wvanbergen/kazoo-go"

	"github.com/open-falcon/falcon-plus/modules/kafka_consumer/g"
	"github.com/open-falcon/falcon-plus/modules/kafka_consumer/proc"
	"github.com/open-falcon/falcon-plus/modules/kafka_consumer/sender"
)

var (
	lowGroup       *consumergroup.ConsumerGroup
	zookeeperNodes []string
)

func lowInitGroup() error {
	g.Logger.Info("start to init consumer group of low version kafka")
	groupCfg := consumergroup.NewConfig()
	cfg := g.Config()
	if cfg.Consumer.Group == "" {
		return errors.New("kafka group name in config is empty")
	}
	if cfg.Consumer.Zookeeper == "" {
		return errors.New("kafka zookeeper in config is empty")
	}
	if len(cfg.Consumer.Topics) < 0 {
		return errors.New("kafka topics in config is empty")
	}

	if cfg.Consumer.Offset == "oldest" {
		groupCfg.Offsets.Initial = sarama.OffsetOldest
	} else {
		groupCfg.Offsets.Initial = DEFAULT_OFFSET
	}

	if cfg.Consumer.OffsetTimeout <= 0 {
		groupCfg.Offsets.ProcessingTimeout = DEFAULT_TIMEOUT
	} else {
		groupCfg.Offsets.ProcessingTimeout = time.Duration(cfg.Consumer.OffsetTimeout) * time.Second
	}

	groupCfg.Consumer.Return.Errors = true

	zookeeperNodes, groupCfg.Zookeeper.Chroot = kazoo.ParseConnectionString(cfg.Consumer.Zookeeper)
	var err error
	lowGroup, err = consumergroup.JoinConsumerGroup(cfg.Consumer.Group, cfg.Consumer.Topics, zookeeperNodes, groupCfg)

	if err != nil {
		lowGroup = nil
		return err
	}
	return nil
}

func lowRun() {
	if lowGroup == nil {
		g.Logger.Error("run kafka consumer group, lowGroup object is nil")
	}
	// init semaphore
	concurrent := g.Config().Consumer.Concurrent

	if concurrent < 1 {
		concurrent = 1
	}

	eventCount := 0

	sema := nsema.NewSemaphore(concurrent)
	for message := range lowGroup.Messages() {
		if g.Config().Debug {
			g.Logger.Debugf("[DEBUG] %d 1 msg topic is: %s, key is %s, value is %s",
				eventCount, message.Topic, string(message.Key), string(message.Value))
		}
		sema.Acquire()
		go func(msg *sarama.ConsumerMessage) {
			defer sema.Release()
			if g.Config().Debug {
				g.Logger.Debugf("%d 2 msg topic is: %s, key is %s, value is %s",
					eventCount, msg.Topic, string(msg.Key), string(msg.Value))
			}
			sender.Push2TrendSendQueue(string(msg.Value))
			proc.ConsumeCnt.Incr()
			if g.Config().Debug {

				offsets := make(map[string]map[int32]int64)
				if offsets[message.Topic] == nil {
					offsets[message.Topic] = make(map[int32]int64)
				}

				if offsets[message.Topic][message.Partition] != 0 && offsets[message.Topic][message.Partition] != message.Offset-1 {
					g.Logger.Debugf("Unexpected offset on %s:%d. Expected %d, found %d, diff %d.\n", message.Topic, message.Partition, offsets[message.Topic][message.Partition]+1, message.Offset, message.Offset-offsets[message.Topic][message.Partition]+1)
				}

				offsets[message.Topic][message.Partition] = message.Offset

				g.Logger.Debugf("[DEBUG] %d , %+v 3", eventCount, offsets)
			}
			g.Logger.Debugf("Get message: %s\n", string(msg.Value))
			if g.Config().Debug {
				g.Logger.Debugf("[DEBUG] %d 4 msg topic is: %s, key is %s, value is %s",
					eventCount, msg.Topic, string(msg.Key), string(msg.Value))
			}
			err := lowGroup.CommitUpto(msg)

			if err != nil {
				g.Logger.Debugf("[ERROR] CommitUpto: %s", err)
			}


			if g.Config().Debug {
				g.Logger.Debugf("[DEBUG] %d 5 finished.", eventCount)
			}
			eventCount += 1
		}(message)
	}
}

func lowErrorPrinter() {
	if lowGroup == nil {
		g.Logger.Error("run kafka consumer group, lowGroup object is nil")
	}
	for err := range lowGroup.Errors() {
		g.Logger.Errorf("low consumer group error: %s", err.Error())
	}
}

func lowStop() {
	if lowGroup != nil {
		if err := lowGroup.Close(); err != nil {
			g.Logger.Errorf("Error closing low consumer group :%s", err.Error())
		}
	}
}
